{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install numpy pandas scipy plotly scikit-learn lempel_ziv_complexity\n",
    "#%pip install jupytext\n",
    "import sys\n",
    "sys.executable\n",
    "\n",
    "# permutation entropy\n",
    "#%pip install ordpy\n",
    "#%pip install antropy\n",
    "#%pip install pandas\n",
    "#%pip install plotly\n",
    "#%pip install jupyter-dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy import signal\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.signal import hilbert \n",
    "#from lempel_ziv_complexity import lempel_ziv_complexity\n",
    "import ordpy\n",
    "import antropy\n",
    "\n",
    "from mt_spectrogram import multitaper_spectrogram, nanpow2db\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "def load_eeg(json_filename, line_freq=60):\n",
    "    with open(json_filename) as fp:\n",
    "        jsn = json.load(fp)\n",
    "    #print(f'start: {jsn[\"start_ts\"]}, end: {jsn[\"end_ts\"]}, metadata: {jsn[\"metadata\"]}')\n",
    "    \n",
    "    dfs = []\n",
    "    assert jsn[\"eeg\"][0][0][\"timestamp\"] == jsn[\"eeg\"][1][0][\"timestamp\"]\n",
    "    assert jsn[\"eeg\"][0][0][\"index\"] == jsn[\"eeg\"][1][0][\"index\"]\n",
    "    # Should we use the eeg timestamp delta from start_ts? (It's about 40ms)\n",
    "    print((jsn[\"start_ts\"] - jsn[\"eeg\"][0][0][\"timestamp\"]) / 1000)\n",
    "    seq_start = jsn[\"eeg\"][0][0][\"index\"]\n",
    "    for chan in jsn[\"eeg\"]:\n",
    "        for e in chan:\n",
    "            tmpdf = pd.DataFrame([{\"electrode\": e[\"electrode\"], \"value\": s,} \n",
    "                                  for i, s in enumerate(e[\"samples\"])])\n",
    "            relseq_time = (e[\"index\"] - seq_start) * EEG_DT * 12\n",
    "            tmpdf[\"reltime\"] = [EEG_DT * i + relseq_time for i in range(12)]\n",
    "            dfs.append(tmpdf)\n",
    "    eeg_df = pd.concat(dfs).pivot(index=\"reltime\", columns=\"electrode\", values=\"value\")\n",
    "    electrode_name_map = {i: n for i, n in enumerate(jsn['metadata']['electrodeNames'])}\n",
    "    eeg_df.rename(columns=electrode_name_map, inplace=True)\n",
    "    \n",
    "    # notch-filter eeg\n",
    "    if line_freq:\n",
    "        b, a = signal.iirnotch(line_freq, Q=30, fs=EEG_FS)\n",
    "        for e in eeg_df.columns:\n",
    "            eeg_df[e] = signal.filtfilt(b, a, eeg_df[e])\n",
    "    \n",
    "    dfs = []\n",
    "    assert jsn[\"gyro\"][0][\"sequenceId\"] == jsn[\"accel\"][0][\"sequenceId\"]\n",
    "    seq_start = jsn[\"accel\"][0][\"sequenceId\"]\n",
    "    for a, g in zip(jsn['accel'], jsn['gyro']):\n",
    "        adf = pd.json_normalize(a[\"samples\"]).rename(columns=dict(x=\"acc_x\", y=\"acc_y\", z=\"acc_z\"))\n",
    "        gdf = pd.json_normalize(g[\"samples\"]).rename(columns=dict(x=\"gyr_x\", y=\"gyr_y\", z=\"gyr_z\"))\n",
    "        tmpdf = pd.concat((adf, gdf), axis=1)\n",
    "        relseq_time = (a[\"sequenceId\"] - seq_start) * MOT_DT * 3\n",
    "        tmpdf[\"reltime\"] = [MOT_DT * i + relseq_time for i in range(3)]\n",
    "        dfs.append(tmpdf)\n",
    "        #tmpdf['samp_offset'] = [samp_offset for i in tmpdf.index]\n",
    "        #tmpdf['start'] = jsn[\"start_ts\"]\n",
    "    motion_df = pd.concat(dfs).set_index(\"reltime\")\n",
    "    \n",
    "    dfs = []\n",
    "    # all timestamps are identical for ppg. And they lead the global start_ts by a bit.\n",
    "    print((jsn[\"start_ts\"] - jsn[\"ppg\"][0][\"timestamp\"]) / 1000)\n",
    "    seq_start = jsn[\"ppg\"][0][\"index\"]\n",
    "    for p in jsn[\"ppg\"]:\n",
    "        tmpdf = pd.DataFrame([{\"channel\": p[\"ppgChannel\"], \"ppg\": s,} \n",
    "                              for i, s in enumerate(p[\"samples\"])])\n",
    "        relseq_time = (p[\"index\"] - seq_start) * PPG_DT * 6\n",
    "        tmpdf[\"reltime\"] = [PPG_DT * i + relseq_time for i in range(6)]\n",
    "        dfs.append(tmpdf)\n",
    "    ppg_df = pd.concat(dfs).pivot(index=\"reltime\", columns=\"channel\", values=\"ppg\")\n",
    "    ppg_df.rename(columns={k: f\"ppg{k}\" for k in ppg_df.columns}, inplace=True)\n",
    "    \n",
    "    return jsn['metadata'], eeg_df, motion_df, ppg_df\n",
    "\n",
    "\n",
    "def calc_bands_power(x, dt, bands):\n",
    "    f, psd = signal.welch(x, fs=1. / dt)\n",
    "    power = {band: np.abs(np.mean(psd[np.where((f >= lf) & (f <= hf))])) \n",
    "                          for band, (lf, hf) in bands.items()}\n",
    "    return power\n",
    "\n",
    "\n",
    "def lzc(x):\n",
    "    \"\"\"\n",
    "    Compute the Lempel-Ziv Complexity on a timeseries x of real numbers.\n",
    "    This is computed by taking the analytical signal of x (using \n",
    "    scipy.signal.hilbert) and creating a series of bits by thresholding\n",
    "    with meadian of the amplitude.\n",
    "    \"\"\"\n",
    "    h = hilbert(x)\n",
    "    amp = np.abs(h)\n",
    "    bitstr = ''.join([str(b) for b in (amp > np.median(amp)).astype(int)])\n",
    "    complexity = antropy.lziv_complexity(bitstr)\n",
    "    ph = np.angle(h)\n",
    "    bitstr = ''.join([str(b) for b in (ph > np.median(ph)).astype(int)])\n",
    "    ph_complexity = antropy.lziv_complexity(bitstr)\n",
    "    return complexity, ph_complexity\n",
    "\n",
    "\n",
    "def logistic(a=4, n=100000, x0=0.4):\n",
    "    x = np.zeros(n)\n",
    "    x[0] = x0\n",
    "    for i in range(n-1):\n",
    "        x[i+1] = a*x[i]*(1-x[i])\n",
    "    return(x)\n",
    "\n",
    "EEG_FS = 256\n",
    "MOT_FS = 52\n",
    "PPG_FS = 64\n",
    "EEG_DT = 1 / EEG_FS\n",
    "MOT_DT = 1 / MOT_FS\n",
    "PPG_DT = 1 / PPG_FS\n",
    "!ls data/Muse*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORK IN PROGRESS\n",
    "# may be able to simplify data loading for eeg and ppg\n",
    "def parse_jsn(jsn, dt, nsamp, seq_name=\"index\", chan_name=\"electrode\"):\n",
    "    dfs = []\n",
    "\n",
    "    seq_start = jsn[0][seq_name]\n",
    "    for d in jsn:\n",
    "        tmpdf = pd.DataFrame([{\"chan\": d[chan_name], \"value\": s,} \n",
    "                              for i, s in enumerate(d[\"samples\"])])\n",
    "        relseq_time = (d[\"index\"] - seq_start) * dt * nsamp\n",
    "        tmpdf[\"reltime\"] = [dt * i + relseq_time for i in range(nsamp)]\n",
    "        dfs.append(tmpdf)\n",
    "    df = pd.concat(dfs).pivot(index=\"reltime\", chan_name=\"electrode\", values=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata, eeg_df, motion_df, ppg_df = load_eeg(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.line(eeg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.line(motion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.line(ppg_df, y=\"ppg_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.random.seed(1234567)\n",
    "x = np.random.normal(size=3000)\n",
    "# Permutation entropy\n",
    "print(antropy.perm_entropy(x, normalize=True))\n",
    "# Spectral entropy\n",
    "print(antropy.spectral_entropy(x, sf=100, method='welch', normalize=True))\n",
    "# Singular value decomposition entropy\n",
    "print(antropy.svd_entropy(x, normalize=True))\n",
    "# Approximate entropy\n",
    "print(antropy.app_entropy(x))\n",
    "# Sample entropy\n",
    "print(antropy.sample_entropy(x))\n",
    "# Hjorth mobility and complexity\n",
    "print(antropy.hjorth_params(x))\n",
    "# Number of zero-crossings\n",
    "print(antropy.num_zerocross(x))\n",
    "# Lempel-Ziv complexity\n",
    "print(antropy.lziv_complexity('01111000011001', normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"MuseS-5743_2023-05-05T19_30_08.185Z.json\"\n",
    "fn = f'./data/{fn}'\n",
    "with open(fn) as fp:\n",
    "    jsn = json.load(fp)\n",
    "(jsn.keys(), jsn['accel'][0].keys(), jsn['ppg'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = load_eeg(fn)\n",
    "EEG_ELECTRODES = edf.electrode.unique()\n",
    "raw = edf.pivot(index=['reltime'], columns=['electrode'], values=['samp']).reset_index()\n",
    "raw.columns = [c[1] if c[1] != '' else c[0] for c in raw.columns]\n",
    "raw.dropna(inplace=True)\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "Sxx, t, f, meta = multitaper_spectrogram(eeg_df.AF7.values, EEG_FS, freq_range=(0, 40), ncores=-1)\n",
    "\n",
    "fig.add_trace(go.Heatmap(x=t, y=f, z=Sxx.clip(-5, 5), colorscale='Solar'))\n",
    "fig.update_layout(title='Average Multitaper Spectrogram', \n",
    "                  font=dict(size=18),\n",
    "                  yaxis=dict(title='Frequency (Hz)'), \n",
    "                  xaxis=dict(title='Time from start (seconds)'),\n",
    "                  width=900, height=500)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px.line(motion_df, y=[\"gyr_x\", \"gyr_y\", \"gyr_z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca, cp = lzc(raw.AF7)\n",
    "print(ca, cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = [logistic(a) for a in [3.05, 3.55, 4]]\n",
    "time_series += [np.random.normal(size=100000)]\n",
    "\n",
    "HC = [ordpy.complexity_entropy(series, dx=4) for series in time_series]\n",
    "HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordpy.permutation_entropy?\n",
    "#ordpy.complexity_entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "x = np.sin(np.linspace(0, 100 * np.pi, n)) + np.random.randn(n) * 0.0\n",
    "c = antropy.lziv_complexity(x)\n",
    "ce = ordpy.complexity_entropy(x)\n",
    "print(c, ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequenceId is the \"timestamp\" and \n",
    "tmpdf = pd.json_normalize(jsn['accel'])\n",
    "tmpdf = tmpdf.explode(column=['samples']) #.reset_index(drop=True)\n",
    "tmpdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = {'cris': './data/MuseS-4DD2_1680820272258.json', \n",
    "       'bob': './data/MuseS-5743_1680820272258.json',\n",
    "       'patrick': './data/MuseS-5C4F_1680820272258.json'}\n",
    "\n",
    "dfs = []\n",
    "for uid, fn in fns.items():\n",
    "    tmpdf = load_eeg(fn)\n",
    "    #tmpdf[\"user_id\"] = uid\n",
    "    dfs.append(tmpdf)\n",
    "\n",
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "EEG_ELECTRODES = dfs[idx].electrode.unique()\n",
    "raw = dfs[idx].pivot(index=['reltime'], columns=['electrode'], values=['samp']).reset_index()\n",
    "raw.columns = [c[1] if c[1] != '' else c[0] for c in raw.columns]\n",
    "raw.dropna(inplace=True)\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = int(round(8 * EEG_FS))\n",
    "stepwin = int(round(1 * EEG_FS))\n",
    "y = raw[EEG_ELECTRODES].rolling(window=win, center=True, step=stepwin).apply(lzc)\n",
    "y[\"reltime\"] = raw.reltime.groupby(raw.index // stepwin).mean()\n",
    "px.line(y, x=\"reltime\", y=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = {#'Delta': (0, 4),\n",
    "         'Theta': (4, 8),\n",
    "         'Alpha': (8, 12),\n",
    "         'Beta': (12, 30),\n",
    "         'Gamma': (30, 55),\n",
    "         'High-gamma': (65, 100)}\n",
    "\n",
    "eeg_pow = calc_bands_power(raw.AF7, EEG_DT, bands)\n",
    "fig = go.Figure(go.Bar(x=[v for v in eeg_pow.values()], y=[k for k in eeg_pow], orientation='h'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "Sxx, t, f, meta = multitaper_spectrogram(raw.AF7.values, EEG_FS, freq_range=(0, 120), ncores=-1)\n",
    "\n",
    "fig.add_trace(go.Heatmap(x=t, y=f, z=Sxx.clip(-5, 5), colorscale='Solar'))\n",
    "fig.update_layout(title='Average Multitaper Spectrogram', \n",
    "                  font=dict(size=18),\n",
    "                  yaxis=dict(title='Frequency (Hz)'), \n",
    "                  xaxis=dict(title='Time from start (seconds)'))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = {#'Delta': (0, 4),\n",
    "         'Theta': (4, 8),\n",
    "         'Alpha': (8, 12),\n",
    "         'Beta': (12, 30),\n",
    "         'Gamma': (30, 55),\n",
    "         'High-gamma': (65, 100)}\n",
    "\n",
    "eeg_pow = calc_bands_power(raw.AF7, EEG_DT, bands)\n",
    "fig = go.Figure(go.Bar(x=[v for v in eeg_pow.values()], y=[k for k in eeg_pow], orientation='h'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "Sxx, t, f, meta = multitaper_spectrogram(raw.AF7.values, EEG_FS, freq_range=(0, 120), ncores=-1)\n",
    "\n",
    "fig.add_trace(go.Heatmap(x=t, y=f, z=Sxx.clip(-5, 5), colorscale='Solar'))\n",
    "fig.update_layout(title='Average Multitaper Spectrogram', \n",
    "                  font=dict(size=18),\n",
    "                  yaxis=dict(title='Frequency (Hz)'), \n",
    "                  xaxis=dict(title='Time from start (seconds)'))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPERSEG = 64\n",
    "#IDX = (20.0, 120.0, 145.0, 300.0)\n",
    "IDX = (1.0, 20.0, 25.0, 50.0)\n",
    "\n",
    "fig = go.Figure()\n",
    "idx = (raw.reltime > IDX[0]) & (raw.reltime < IDX[1])\n",
    "f, Cxy = signal.coherence(raw.AF7[idx] + raw.TP9[idx], raw.AF8[idx] + raw.TP10[idx], 256, nperseg=NPERSEG)\n",
    "fig.add_trace(go.Scatter(x=f, y=Cxy, mode='lines', name=f'Task'))\n",
    "idx = (raw.reltime > IDX[2]) & (raw.reltime < IDX[3])\n",
    "f, Cxy = signal.coherence(raw.AF7[idx] + raw.TP9[idx], raw.AF8[idx] + raw.TP10[idx], 256, nperseg=NPERSEG)\n",
    "fig.add_trace(go.Scatter(x=f, y=Cxy, mode='lines', name=f'Rest'))\n",
    "    \n",
    "fig.update_layout(yaxis= {'type': 'log', 'title': 'Coherence'},\n",
    "                  xaxis_title='Frequency',\n",
    "                  legend={'font': {'size': 14}, \n",
    "                          #'title': {'font': {'size': 16}, 'text': 'Measure'},\n",
    "                          'yanchor': 'bottom', 'y': 0.05, 'xanchor': 'center', 'x': 0.5},\n",
    "                  title='Fronto-temporal Coherence',\n",
    "                  font={'size': 18})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPERSEG = 64\n",
    "#IDX = (20.0, 120.0, 145.0, 300.0)\n",
    "IDX = (1.0, 16.0, 22.0, 55.0)\n",
    "\n",
    "fig = go.Figure()\n",
    "for k in [('E0', 'E1'), ('E3', 'E2')]:\n",
    "    idx = (raw.reltime > IDX[0]) & (raw.reltime < IDX[1])\n",
    "    f, Cxy = signal.coherence(raw[k[0]][idx], raw[k[1]][idx], 256, nperseg=NPERSEG)\n",
    "    fig.add_trace(go.Scatter(x=f, y=Cxy, mode='lines', name=f'Task {k[0]} v. {k[1]}'))\n",
    "    idx = (raw.reltime > IDX[2]) & (raw.reltime < IDX[3])\n",
    "    f, Cxy = signal.coherence(raw[k[0]][idx], raw[k[1]][idx], 256, nperseg=NPERSEG)\n",
    "    fig.add_trace(go.Scatter(x=f, y=Cxy, mode='lines', name=f'Rest {k[0]} v. {k[1]}'))\n",
    "    \n",
    "fig.update_layout(yaxis= {'type': 'log', 'title': 'Coherence'},\n",
    "                  xaxis_title='Frequency',\n",
    "                  legend={'font': {'size': 14}, \n",
    "                          #'title': {'font': {'size': 16}, 'text': 'Measure'},\n",
    "                          'yanchor': 'bottom', 'y': 0.05, 'xanchor': 'center', 'x': 0.5},\n",
    "                  title='Coherence',\n",
    "                  font={'size': 18})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy_ext import rolling_apply\n",
    "\n",
    "def coherence(x, y):\n",
    "    f, Cxy = signal.coherence(x, y, 256, nperseg=NPERSEG)\n",
    "    return f, Cxy\n",
    "\n",
    "df = raw.copy().set_index('samp')\n",
    "\n",
    "#df[['f', 'Cxy']] = rolling_apply(coherence, , df.AF7.values, df.TP9.values)\n",
    "#locdf[['dist', 'bearing']] = pd.DataFrame(np.row_stack(np.vectorize(dist_az, otypes=['O'])(\n",
    "#    locdf['latitude'], locdf['longitude'], locdf['homelat'], locdf['homelon'])), index=locdf.index)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=3, cols=1, subplot_titles=('Sensors', 'Raw EEG', 'Muse Bands'))\n",
    "#fig = go.Figure(go.Bar(y=statdf.index, x=statdf['User-days'], orientation='h'))\n",
    "\n",
    "for v in ['x', 'y', 'z']:\n",
    "    fig.add_trace(go.Scatter(x=acc.samp, y=acc[v], name=f'Accel {v.upper()}'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=gyr.samp, y=gyr[v], name=f'Gyro {v.upper()}', yaxis='y2'), row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Time\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Accelerometer (m/s/s)\", row=1, col=1, secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"Gyro (rad/s)\", row=1, col=1, secondary_y=True, anchor='x',\n",
    "                 overlaying='y', side='right')\n",
    "\n",
    "for v in ['TP9', 'AF7', 'AF8', 'TP10']: #, 'Aux']:\n",
    "    fig.add_trace(go.Scatter(x=raw.samp, y=raw[v], name=f'{v.upper()}', opacity=0.5), row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Time\", row=2, col=1)\n",
    "\n",
    "#for v in ['delta', 'theta', 'alpha', 'beta', 'gamma']:\n",
    "#    tmp = band.loc[bands.band == v, :].copy().reset_index()\n",
    "#    tmp['samp'] = tmp.index / SEN_FS\n",
    "#    fig.add_trace(go.Scatter(x=tmp.samp, y=tmp.AF7 + tmp.AF8 + tmp.TP9 + tmp.TP10, name=f'{v}'), row=3, col=1)\n",
    "#fig.update_xaxes(title_text=\"Time\", row=3, col=1)\n",
    "\n",
    "fig.update_layout(height=1000, \n",
    "                  title='Muse EEG', \n",
    "                  #showlegend=False,\n",
    "                  font={'size': 18})\n",
    "\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression as MIR\n",
    "\n",
    "N = 10000\n",
    "X = np.random.randn(N, 1)\n",
    "y = X[:, 0] +  np.random.randn(N) * 0.01\n",
    "mi_score = MIR(X, y)\n",
    "print(mi_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python10",
   "language": "python",
   "name": "python10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
